{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 08/03/2023 - Lab 01: Introduction to Deep Learning"
      ],
      "metadata": {
        "id": "8Orh_3T4Cd9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Neural Networks require high parallel computation, you need to activate GPU Runtime. Click Runtime -> Change Runtime Time -> GPU. Note that you will be automatically disconnected if you don't run any code for some minutes (or - personal experience - if you run code for more than a certain time threshold)."
      ],
      "metadata": {
        "id": "BwjzydBPuNkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!nvidia-smi  # Bash command to see GPU information"
      ],
      "metadata": {
        "id": "edyZj8sD_S2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf3dd78-37a0-4a78-e52d-0213ab28aca5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 24 13:09:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, COLAB allows bash commands, they're written preceded by a '!'"
      ],
      "metadata": {
        "id": "uVE2kYNrDxJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Vf4befvPYB",
        "outputId": "cb3c4e52-e11d-46f9-ef83-45e9b1cd544d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading: Fashion MNIST\n",
        "Collection of Grayscale Images 28x28 obtained from Zalando's article images. Each image is associated with a label from 10 classes. On the github page you can find more details: https://github.com/zalandoresearch/fashion-mnist. Keras has already built-in data, included this, so we can use the built-in functionalities to load the dataset in memory\n"
      ],
      "metadata": {
        "id": "LBbtPqFWCkMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(xtrain, ytrain), (xtest, ytest) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "VdwTvSLuDHwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5de88b-d8ff-4c7e-b6f8-cbfd22e69c1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.shape, xtest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvVYEXAUD51F",
        "outputId": "7a775913-9d5d-4dc5-ac63-18ad8ba2bb24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xtrain.max(), xtrain.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm1cRh85ETVt",
        "outputId": "7c122f27-3efb-480e-f9ce-b057f647f04b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be useful to normalize the data, as it is a small model. It improves the speed in training phase and can also improve performance. We will use MinMax feature scaling. "
      ],
      "metadata": {
        "id": "Us0UvQw5EreU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_data = lambda X: (X-X.min())/(X.max()-X.min())"
      ],
      "metadata": {
        "id": "Yp7Z23PxE9K7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = normalize_data(xtrain)\n",
        "xtest = normalize_data(xtest)\n",
        "print(xtrain.min(), xtrain.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA91K_MmFFTl",
        "outputId": "0e566184-e799-4870-ca60-69d4e7a94b92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytrain[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ueipqOsIbIR",
        "outputId": "bff3e7f3-3c23-46e0-e271-6a06c4fdf9be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(ytrain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY_iRbf4FqpR",
        "outputId": "e1371a66-ec4a-42bc-b255-f8b0306962fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of ytrain is one of 10 different categories. We want to build a model to associate a category to an image. We want to encode these categories in a way in which the model can comprehend them better. We will use OneHotEncoding (mapping a continuous value into a vector that in this case will have length 10 and will be all 0 except for 1 in the position corresponding to the original category). "
      ],
      "metadata": {
        "id": "WXxoXnl7HRWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "8O82kPr1IVFG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "print(ytrain[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOij6aDrH5Wx",
        "outputId": "ac638f2c-4b7c-45d9-d2ec-349db7808694"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This concludes the section on data preprocessing"
      ],
      "metadata": {
        "id": "DW67noVpIrZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the Model"
      ],
      "metadata": {
        "id": "NGlW1XaHI7bN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We work with Keras, API built on top of Tensorflow. We can use Sequential API and Functional API. \n",
        "Summary of layers:\n",
        "\n",
        "\n",
        "*   Input -> first layer of the network\n",
        "*   Flatten -> utility layer that reshapes data to a 1D array. \n",
        "* Reshape -> utility layer that reshapes the input in whatever way you want, provided that dimensions match\n",
        "* Dense -> basic layer. Stands for the fully connected layer.\n",
        "\n"
      ],
      "metadata": {
        "id": "JO0b1_x2JABF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input"
      ],
      "metadata": {
        "id": "FdjNk7YbJLV1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Sequential API, we simply feed to Sequential() a list of all the layers, in the order in which the data should flow. In the following case, you feed in input the image as it is, and then obtain a (10, ) array. We will use the Softmax function to convert the output layer values in probability values. From this you can easily single out the most probable value. Issue with the Sequential API: it's a straightforward approach. You cannot \"skip\""
      ],
      "metadata": {
        "id": "ygaA-T5dJqo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(), Dense(64), Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Zk8sHWItJjsB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Functional API, differently from the Sequential, we need to define the input layer, so state what the network should expect; also, we need not only to specify which layers you need, but also how the layers are concatenated. This will become useful in case we want to use Residual Networks."
      ],
      "metadata": {
        "id": "AxWl1h0eMAGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, output_shape):\n",
        "  input = Input(input_shape)\n",
        "  flatten = Flatten()(input) # it kinda looks like a function\n",
        "\n",
        "  dense_1 = Dense(64, activation='relu')(flatten) # this is something good we can do. Useful working with images\n",
        "  dense_2 = Dense(10, activation='softmax')(dense_1)\n",
        "\n",
        "  model = Model(inputs=input, outputs=dense_2)\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "CJmj26ePLjJr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function summary() gives in output the summary of all the models: we can see the total number of parameters etc."
      ],
      "metadata": {
        "id": "AN6Bf0iCOUqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model((28,28), 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPB34KcLOOAV",
        "outputId": "70a6ce41-a476-4aa2-d907-f6d157e1e557"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can actually train our model. We must specify the loss function and the optimizer. In the compile() operation, you must pass the configuration of the model. We will use Adam (very standard), Categorical Cross Entropy, which is often used on Multi-Label Classification, as Evaluation Metric we will use accuracy. Keras provides a string to call all these optimizers, which is bad because we can't modify the hyperparameters (e.g. Adam). To do this, you must call them with their full name as Tensorflow functions."
      ],
      "metadata": {
        "id": "yhTKKnziRIb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "ePAo4JRXRUka"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(xtrain, ytrain, epochs=10, validation_split=0.1) # we can also deal manually with the Validation split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFmj3OBVR8vL",
        "outputId": "f2441361-23d1-4963-fefd-4d8faeeea0fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 10s 3ms/step - loss: 0.5213 - accuracy: 0.8185 - val_loss: 0.4342 - val_accuracy: 0.8423\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3918 - accuracy: 0.8599 - val_loss: 0.3724 - val_accuracy: 0.8643\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.8721 - val_loss: 0.3754 - val_accuracy: 0.8635\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3293 - accuracy: 0.8794 - val_loss: 0.3408 - val_accuracy: 0.8767\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3137 - accuracy: 0.8857 - val_loss: 0.3440 - val_accuracy: 0.8768\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2968 - accuracy: 0.8910 - val_loss: 0.3423 - val_accuracy: 0.8753\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2851 - accuracy: 0.8950 - val_loss: 0.3359 - val_accuracy: 0.8828\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2765 - accuracy: 0.8982 - val_loss: 0.3435 - val_accuracy: 0.8790\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2651 - accuracy: 0.9030 - val_loss: 0.3472 - val_accuracy: 0.8792\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2576 - accuracy: 0.9056 - val_loss: 0.3556 - val_accuracy: 0.8740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can save the results in a 'history' variable to then graph it. Then we want to validate the results"
      ],
      "metadata": {
        "id": "yuDOPq8ISdCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xtest, ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MSJBTocScuB",
        "outputId": "74ac9df6-cd0b-4d4f-f155-b19baed6bae5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3836 - accuracy: 0.8629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38359108567237854, 0.8629000186920166]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2S2ZXZ_nSxxC",
        "outputId": "2e625d51-562c-4159-b995-443d44b90c13"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorboard is a tool to analyze interactively the model. Callback functions are tools to do operations while training (e.g. TensorBoard or EarlyStopping). In EarlyStopping, you can establish a target value to monitor (e.g. accuracy or loss) and after how many epochs stop the iterations. It allows to not care about the epoch value and reduce the risk of overfitting"
      ],
      "metadata": {
        "id": "LgJzcpbyTL9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "iUyuQzBMTfkU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=f'logs/fit/{str(datetime.datetime.now())}')\n",
        "model = build_model((28,28), 10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "history = model.fit(xtrain, ytrain, epochs=10, validation_split=0.1, callbacks=[tb_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxDBVyOOTh3g",
        "outputId": "c672ef03-2d3e-4aa3-b3e9-c50963136ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 7s 3ms/step - loss: 0.5292 - accuracy: 0.8170 - val_loss: 0.4030 - val_accuracy: 0.8548\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3946 - accuracy: 0.8587 - val_loss: 0.3729 - val_accuracy: 0.8680\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3563 - accuracy: 0.8708 - val_loss: 0.3457 - val_accuracy: 0.8770\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3309 - accuracy: 0.8813 - val_loss: 0.3463 - val_accuracy: 0.8780\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3113 - accuracy: 0.8882 - val_loss: 0.3362 - val_accuracy: 0.8845\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2979 - accuracy: 0.8924 - val_loss: 0.3338 - val_accuracy: 0.8815\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2841 - accuracy: 0.8949 - val_loss: 0.3398 - val_accuracy: 0.8857\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2764 - accuracy: 0.8984 - val_loss: 0.3416 - val_accuracy: 0.8775\n",
            "Epoch 9/10\n",
            " 767/1688 [============>.................] - ETA: 2s - loss: 0.2675 - accuracy: 0.9013"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "mfEh_4oaUbC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}